import openai # OpenAI's official Python library
import logging
from src.e_Infra.j_LlmManager.LlmServiceBase import LlmServiceBase

logger = logging.getLogger(__name__)

class OpenAIService(LlmServiceBase):
    """
    A service class to encapsulate interactions with the OpenAI API,
    adhering to the LlmServiceBase interface.
    """
    DEFAULT_MODEL_NAME = "gpt-3.5-turbo" # A common and effective default

    def __init__(self, api_key: str, model_name: str = None):
        """
        Initializes the OpenAIService.

        Args:
            api_key (str): The OpenAI API key.
            model_name (str, optional): The specific OpenAI model name to use.
                                        Defaults to "gpt-3.5-turbo".
        Raises:
            ValueError: If the API key is not provided.
            RuntimeError: If initialization of the OpenAI client fails.
        """
        if not api_key:
            logger.error("API key not provided for OpenAIService initialization.")
            raise ValueError("API key for OpenAI must be provided.")

        self.api_key = api_key
        self.model_name = model_name or self.DEFAULT_MODEL_NAME

        try:
            # The OpenAI library uses the OPENAI_API_KEY environment variable by default if api_key is not passed
            # directly to the client constructor. Or, you can pass it explicitly.
            # For clarity and consistency with other services, we'll pass it explicitly.
            self.client = openai.OpenAI(api_key=self.api_key)
            logger.info(f"OpenAIService initialized successfully for model: {self.model_name}.")
        except Exception as e:
            logger.error(f"Error during OpenAIService initialization (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"Failed to initialize OpenAI Service (model: {self.model_name}): {e}")

    def generate_text(self, prompt: str) -> str:
        """
        Generates text using the configured OpenAI model.

        Args:
            prompt (str): The prompt to send to the OpenAI API.
                          This will be used as the content of a user message in the chat completion.

        Returns:
            str: The text response generated by the OpenAI API.

        Raises:
            RuntimeError: If there's an error during text generation.
        """
        if not prompt:
            logger.warning("Generate_text called with an empty prompt.")
            return ""

        try:
            # Using ChatCompletion for newer models. For older models like text-davinci-003,
            # you might use openai.Completion.create.
            # Modern best practice is to use ChatCompletion.
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "user", # Or construct a more complex message history if needed
                        "content": prompt,
                    }
                ],
                model=self.model_name,
            )
            # Ensure there's a choice and a message with content
            if chat_completion.choices and chat_completion.choices[0].message and chat_completion.choices[0].message.content:
                return chat_completion.choices[0].message.content.strip()
            else:
                logger.error("OpenAI API returned an unexpected response structure or empty content.")
                raise RuntimeError("OpenAI API returned no content.")
        except openai.APIError as e: # Catch specific OpenAI errors
            logger.error(f"OpenAI API error during text generation (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"Failed to generate text using OpenAI (model: {self.model_name}): {e}")
        except Exception as e: # Catch other potential errors
            logger.error(f"Unexpected error during OpenAI text generation (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"An unexpected error occurred with OpenAI (model: {self.model_name}): {e}")

    def check_connection(self) -> bool:
        """
        Performs a lightweight check to see if the configured API key
        is valid and can connect to the OpenAI service by listing available models.
        Note: Listing models might require specific permissions for the API key.
        A simpler check might be a very short, inexpensive generation if listing models is problematic.
        """
        try:
            # Listing models is a common way to check API key validity.
            self.client.models.list()
            logger.info("OpenAI API connection check successful: Models listed.")
            return True
        except openai.APIError as e:
            logger.error(f"OpenAI API connection check failed: {e}", exc_info=True)
            return False
        except Exception as e: # Catch other potential errors during the check
            logger.error(f"Unexpected error during OpenAI connection check: {e}", exc_info=True)
            return False
