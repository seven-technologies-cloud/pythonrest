import openai # OpenAI's official Python library
import logging
from src.e_Infra.j_LlmManager.LlmServiceBase import LlmServiceBase

logger = logging.getLogger(__name__)

class OpenAIService(LlmServiceBase):
    """
    A service class to encapsulate interactions with the OpenAI API,
    adhering to the LlmServiceBase interface.
    """
    DEFAULT_MODEL_NAME = "gpt-3.5-turbo"
    DEFAULT_TEMPERATURE = 0.7

    def __init__(self, api_key: str, model_name: str = None, temperature: float = None):
        """
        Initializes the OpenAIService.

        Args:
            api_key (str): The OpenAI API key.
            model_name (str, optional): The specific OpenAI model name to use. Defaults to "gpt-3.5-turbo".
            temperature (float, optional): Sampling temperature. Defaults to self.DEFAULT_TEMPERATURE.
        Raises:
            ValueError: If the API key is not provided or temperature is invalid.
            RuntimeError: If initialization of the OpenAI client fails.
        """
        if not api_key:
            logger.error("API key not provided for OpenAIService initialization.")
            raise ValueError("API key for OpenAI must be provided.")

        self.api_key = api_key
        self.model_name = model_name or self.DEFAULT_MODEL_NAME

        if temperature is not None:
            try:
                self.temperature = float(temperature)
                if not (0.0 <= self.temperature <= 2.0): # OpenAI typical range
                     logger.warning(f"Temperature {self.temperature} for OpenAI is outside typical range (0.0-2.0). Using it anyway.")
            except ValueError:
                logger.error(f"Invalid temperature value '{temperature}'. Must be a float. Using default.")
                self.temperature = self.DEFAULT_TEMPERATURE
        else:
            self.temperature = self.DEFAULT_TEMPERATURE

        try:
            self.client = openai.OpenAI(api_key=self.api_key)
            logger.info(f"OpenAIService initialized: model='{self.model_name}', temperature={self.temperature}.")
        except Exception as e:
            logger.error(f"Error during OpenAIService init (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"Failed to initialize OpenAI Service (model: {self.model_name}): {e}")

    def generate_text(self, prompt: str) -> str:
        """
        Generates text using the configured OpenAI model.

        Args:
            prompt (str): The prompt to send to the OpenAI API.
                          This will be used as the content of a user message in the chat completion.

        Returns:
            str: The text response generated by the OpenAI API.

        Raises:
            RuntimeError: If there's an error during text generation.
        """
        if not prompt:
            logger.warning("Generate_text called with an empty prompt.")
            return ""

        try:
            # Using ChatCompletion for newer models. For older models like text-davinci-003,
            # you might use openai.Completion.create.
            # Modern best practice is to use ChatCompletion.
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "user", # Or construct a more complex message history if needed
                        "content": prompt,
                    }
                ],
                model=self.model_name,
                temperature=self.temperature,
                # Add other parameters like max_tokens if needed
            )
            # Ensure there's a choice and a message with content
            if chat_completion.choices and chat_completion.choices[0].message and chat_completion.choices[0].message.content:
                return chat_completion.choices[0].message.content.strip()
            else:
                logger.error("OpenAI API returned an unexpected response structure or empty content.")
                raise RuntimeError("OpenAI API returned no content.")
        except openai.APIError as e: # Catch specific OpenAI errors
            logger.error(f"OpenAI API error during text generation (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"Failed to generate text using OpenAI (model: {self.model_name}): {e}")
        except Exception as e: # Catch other potential errors
            logger.error(f"Unexpected error during OpenAI text generation (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"An unexpected error occurred with OpenAI (model: {self.model_name}): {e}")

    def check_connection(self) -> bool:
        """
        Performs a lightweight check to see if the configured API key
        is valid and can connect to the OpenAI service by listing available models.
        Note: Listing models might require specific permissions for the API key.
        A simpler check might be a very short, inexpensive generation if listing models is problematic.
        """
        try:
            # Listing models is a common way to check API key validity.
            self.client.models.list()
            logger.info("OpenAI API connection check successful: Models listed.")
            return True
        except openai.APIError as e:
            logger.error(f"OpenAI API connection check failed: {e}", exc_info=True)
            return False
        except Exception as e: # Catch other potential errors during the check
            logger.error(f"Unexpected error during OpenAI connection check: {e}", exc_info=True)
            return False
