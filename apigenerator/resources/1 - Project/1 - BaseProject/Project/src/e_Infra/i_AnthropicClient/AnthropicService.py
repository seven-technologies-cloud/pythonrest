import anthropic # Anthropic's official Python library
import logging
from src.e_Infra.j_LlmManager.LlmServiceBase import LlmServiceBase

logger = logging.getLogger(__name__)

class AnthropicService(LlmServiceBase):
    """
    A service class to encapsulate interactions with the Anthropic API,
    adhering to the LlmServiceBase interface.
    """
    # Using a common, recent Haiku model as default. Update as new models become standard.
    DEFAULT_MODEL_NAME = "claude-3-haiku-20240307"

    def __init__(self, api_key: str, model_name: str = None):
        """
        Initializes the AnthropicService.

        Args:
            api_key (str): The Anthropic API key.
            model_name (str, optional): The specific Anthropic model name to use.
                                        Defaults to "claude-3-haiku-20240307".
        Raises:
            ValueError: If the API key is not provided.
            RuntimeError: If initialization of the Anthropic client fails.
        """
        if not api_key:
            logger.error("API key not provided for AnthropicService initialization.")
            raise ValueError("API key for Anthropic must be provided.")

        self.api_key = api_key
        self.model_name = model_name or self.DEFAULT_MODEL_NAME

        try:
            self.client = anthropic.Anthropic(api_key=self.api_key)
            logger.info(f"AnthropicService initialized successfully for model: {self.model_name}.")
        except Exception as e:
            logger.error(f"Error during AnthropicService initialization (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"Failed to initialize Anthropic Service (model: {self.model_name}): {e}")

    def generate_text(self, prompt: str) -> str:
        """
        Generates text using the configured Anthropic model.

        Args:
            prompt (str): The prompt to send to the Anthropic API.
                          This will be used as the content of a user message.

        Returns:
            str: The text response generated by the Anthropic API.

        Raises:
            RuntimeError: If there's an error during text generation.
        """
        if not prompt:
            logger.warning("Generate_text called with an empty prompt.")
            return ""

        try:
            # Anthropic's API uses a `messages` structure.
            # The `max_tokens` parameter is typically required.
            message = self.client.messages.create(
                model=self.model_name,
                max_tokens=2048, # Adjust as needed, consider making configurable
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            # The response structure gives content blocks; typically, the first one is text.
            if message.content and isinstance(message.content, list) and len(message.content) > 0:
                # Assuming the first content block is of type 'text'
                # You might want to iterate or check block types if more complex content is expected
                if hasattr(message.content[0], 'text'):
                    return message.content[0].text.strip()
                else:
                    logger.error("Anthropic API returned a content block without text.")
                    raise RuntimeError("Anthropic API returned no text content in the first block.")
            else:
                logger.error("Anthropic API returned an unexpected response structure or empty content.")
                raise RuntimeError("Anthropic API returned no content.")
        except anthropic.APIError as e: # Catch specific Anthropic errors
            logger.error(f"Anthropic API error during text generation (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"Failed to generate text using Anthropic (model: {self.model_name}): {e}")
        except Exception as e: # Catch other potential errors
            logger.error(f"Unexpected error during Anthropic text generation (model: {self.model_name}): {e}", exc_info=True)
            raise RuntimeError(f"An unexpected error occurred with Anthropic (model: {self.model_name}): {e}")

    def check_connection(self) -> bool:
        """
        Performs a lightweight check for the Anthropic client.
        Anthropic's Python library doesn't have a direct 'list_models' or similar lightweight check
        that doesn't consume message credits without making an actual content generation call.
        A very short, inexpensive prompt is the most reliable way to check.
        Alternatively, we can assume if the client initializes without error, the setup is okay,
        but this doesn't verify the API key's validity against the backend.
        For now, we'll try a very minimal generation call.
        """
        try:
            # Attempt a very short, inexpensive generation call.
            # This will consume a minimal amount of credits but actually tests the API key.
            self.client.messages.create(
                model=self.model_name,
                max_tokens=10,
                messages=[{"role": "user", "content": "Health check."}]
            )
            logger.info("Anthropic API connection check successful (via minimal generation).")
            return True
        except anthropic.APIError as e:
            # Specifically catch authentication errors if possible, though any APIError suggests a problem.
            if isinstance(e, anthropic.AuthenticationError):
                 logger.error(f"Anthropic API connection check failed: AuthenticationError: {e}", exc_info=True)
            else:
                 logger.error(f"Anthropic API connection check failed: APIError: {e}", exc_info=True)
            return False
        except Exception as e:
            logger.error(f"Unexpected error during Anthropic connection check: {e}", exc_info=True)
            return False
